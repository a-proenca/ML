{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f858335e",
   "metadata": {},
   "source": [
    "## Instituto Politécnico de Coimbra\n",
    "## Instituto Superior de Engenharia de Coimbra\n",
    "## Mestrado em Engenharia Informática - Machine Learning\n",
    "## Elaborado por:\n",
    "\n",
    "# André Proença 2016018783\n",
    "\n",
    "# Isabel Castro 2018013160\n",
    "\n",
    "## DATA SET ORIGINAL\n",
    "## [https://archive.ics.uci.edu/ml/datasets/Bank+Marketing](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "5ae4bcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sea\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import string\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca517ec4",
   "metadata": {},
   "source": [
    "## Used functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "67b7de43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randcolor(number):\n",
    "    lista = []\n",
    "    for i in range(number):\n",
    "        color = \"%06x\" % random.randint(0, 0xFFFFFF)\n",
    "        lista.append(color)\n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "24794560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotFigureBoxPlot(columnName,dataset):\n",
    "    plt.figure(figsize=(6,9))\n",
    "    sea.boxplot(x=columnName, data=dataset, color='green')\n",
    "    plt.title(\"Boxplot of {}\" .format(columnName),size=20,color=\"red\")\n",
    "    plt.xlabel(\"{}\".format(columnName),size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "2c2c72ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericAnalysis(columnName, dataframe):\n",
    "    item = dataframe[columnName]\n",
    "\n",
    "    print(\"Mean:\\t\", item.mean())\n",
    "    print(\"Mode:\\t\", item.mode())\n",
    "    print(\"Median:\\t\", item.median())\n",
    "    print(\"Variance:\\t\", item.var())\n",
    "    print(\"Std deviation:\\t\", item.std())\n",
    "    print(\"Percentils (25, 50, 75):\\t\", item.quantile([0, 0.25, 0.5, 0.75, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "559524df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotBarChart(dataset, columnName):\n",
    "    sea.set(style='whitegrid', palette=\"bright\", font_scale=1.1, rc={\"figure.figsize\": [15, 10]})\n",
    "    if(dataset[columnName].dtype != 'object'):\n",
    "        sea.histplot(x=columnName, data=dataset, bins=np.arange(0, 100, 5), kde=True)\n",
    "    else:\n",
    "        sea.histplot(x=columnName, data=dataset, bins=np.arange(0, 100, 5))\n",
    "    plt.title(string.capwords(columnName) + \" \" + \"distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "a8f695d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPieChart(data, labels, title, color=None):\n",
    "    \n",
    "    \n",
    "    fig1, ax1 = plt.subplots()\n",
    "    if (color == None):\n",
    "        plt.style.use('seaborn-pastel')\n",
    "    ax1.pie(data,\n",
    "            labels=labels,\n",
    "            autopct=\"%.1f%%\",\n",
    "            startangle=90,\n",
    "            colors=color,\n",
    "            pctdistance=0.85)\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    ax1.axis('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "085a45be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotBarChartByAgeRange(dataset, columnName, label, title):\n",
    "    ageRange = list(range(15, 95, 5))\n",
    "\n",
    "    plt.figure(figsize=(18, 25))\n",
    "    plt.subplot(3, 2, 1)\n",
    "    dataset.groupby(pd.cut(dataset.age, ageRange))[columnName].mean().plot.bar()\n",
    "    plt.ylabel(label)\n",
    "    plt.title(title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28296aaa",
   "metadata": {},
   "source": [
    "## Dataset reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "a2046705",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDataset = pd.read_csv('bank-full.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5ec98e",
   "metadata": {},
   "source": [
    "### Resampling Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "outputs": [],
   "source": [
    "X = fullDataset.drop('y',axis=1)\n",
    "Y = fullDataset['y']\n",
    "\n",
    "xData,xdataa,yData,ydataa = train_test_split(X,Y,train_size=0.22,stratify=Y)\n",
    "\n",
    "yData=pd.DataFrame(yData,columns=['y'])\n",
    "dataset = xData"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "33de62d1",
   "metadata": {},
   "source": [
    "## Features Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3e5414",
   "metadata": {},
   "source": [
    "### Find the numeric outliers so that we can drop them when we get there"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6b5fc2",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8802c8c3",
   "metadata": {},
   "source": [
    "### Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "300b72f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAMOS DAR DROP A TODAS AS LINHAS COM BALANCE NEGATIVO E VAMOS TAMBEM DAR DROP A LINHAS COM BALANCE MUITO ALTOS\n",
    "dataset.drop(dataset[(dataset['balance']>40000)|(dataset['balance']<0)].index,inplace=True,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1876cf32",
   "metadata": {},
   "source": [
    "# Remover outliers da duration apos analise do boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "85c7b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove data where duration is bigger than 2500\n",
    "dataset.drop(dataset[dataset['duration']>2500].index,inplace=True,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c1b488",
   "metadata": {},
   "source": [
    "### Campaign"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9aad25",
   "metadata": {},
   "source": [
    "# Remover outliers da campaign apos analise do boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "7bf2337f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove data where campaign is bigger than 35\n",
    "dataset.drop(dataset[dataset['campaign']>35].index,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1ede33",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cd0b7af",
   "metadata": {},
   "source": [
    "### Pdays"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Remover outlier pdays"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "aff25338",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all pdays data\n",
    "dataset.drop(\"pdays\",inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af2f259",
   "metadata": {},
   "source": [
    "### Previous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7613b8c0",
   "metadata": {},
   "source": [
    "# Remover outliers previous apos analise do boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "5c8c32dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all data where previous is bigger than 30\n",
    "dataset.drop(dataset[dataset['previous']>30].index,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0645a225",
   "metadata": {},
   "source": [
    "### PoutCome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162d051f",
   "metadata": {},
   "source": [
    "## Stratified sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "outputs": [],
   "source": [
    "\n",
    "# Divide dataset between features e target\n",
    "\n",
    "\n",
    "# Test and train must have similar loans value\n",
    "\n",
    "dataset['binary'] = dataset['loan'].astype(str) + dataset['default'].astype(str)\n",
    "\n",
    "x_train_set, x_test_set , y_train, y_test  = train_test_split(dataset,yData,train_size=0.8, random_state=0, stratify=dataset[['binary']])\n",
    "\n",
    "# Remove binary column because it was only an aux for the split\n",
    "x_train_set = x_train_set.drop(\"binary\",axis=1)\n",
    "x_test_set = x_test_set.drop(\"binary\",axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Enconding categorical data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "b5723c90",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "1028e9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cat = ['age','balance','day','campaign','previous','duration']\n",
    "ordinal_cat = ['month','contact','poutcome']\n",
    "one_hot_cat = ['job','marital','education','default','housing','loan']\n",
    "\n",
    "num_pipe = Pipeline([('scaler',StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline([('onehot',OneHotEncoder(handle_unknown='ignore', sparse=False, drop='if_binary'))])\n",
    "\n",
    "cat_pipe_ordinal = Pipeline([('ordinal_encoder',OrdinalEncoder())])\n",
    "\n",
    "preprocessor = ColumnTransformer([('num_enc',num_pipe,num_cat),('cat_enc',categorical_transformer,one_hot_cat),('ord_enc',cat_pipe_ordinal,ordinal_cat)])\n",
    "\n",
    "x_train_set = preprocessor.fit_transform(x_train_set)\n",
    "x_test_set = preprocessor.fit_transform(x_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05555a0d",
   "metadata": {},
   "source": [
    "### Without pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cd4385",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binary Encoding\n",
    "\n",
    "list_bin = ['default','housing','loan']\n",
    "for i in list_bin:\n",
    "    dataset[i] = LabelBinarizer().fit_transform(dataset[i].values)\n",
    "\n",
    "#Ordinal Encoding\n",
    "\n",
    "list_ordinal=['month','contact','poutcome']\n",
    "for i in list_ordinal:\n",
    "    dataset[i]=LabelEncoder().fit_transform(dataset[i].values)\n",
    "\n",
    "# Dummy Encoding\n",
    "\n",
    "dataset = pd.get_dummies(dataset, columns= ['job','marital','education'])\n",
    "\n",
    "# Reset Index and check dataset again\n",
    "\n",
    "dataset = dataset.reset_index()\n",
    "dataset.drop('index', axis=1, inplace=True)\n",
    "\n",
    "dataset['binary'] = dataset['loan'].astype(str) + dataset['default'].astype(str)\n",
    "\n",
    "x_train_set_np, x_test_set_np , y_train_set_np, y_test_set_np = train_test_split(dataset,datasetTarget,test_size=0.2, random_state=0, stratify=dataset[['binary']])\n",
    "\n",
    "# Binary columns no longer needed\n",
    "x_train_set_np = x_train_set_np.drop(\"binary\",axis=1)\n",
    "x_test_set_np = x_test_set_np.drop(\"binary\",axis=1)\n",
    "\n",
    "\n",
    "#Scaling\n",
    "\n",
    "ss= StandardScaler()\n",
    "\n",
    "x_train_set_np_org = ss.fit_transform(x_train_set_np)\n",
    "x_test_set_np_org = ss.fit_transform(x_test_set_np)\n",
    "\n",
    "x_train_set_np_sc = ss.fit_transform(x_train_set_np[['age','balance','day','duration','campaign','previous']])\n",
    "x_test_set_np_sc = ss.transform(x_test_set_np[['age','balance','day','duration','campaign','previous']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### META 2 ####"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:22<00:00,  1.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "                               Accuracy  Balanced Accuracy ROC AUC  F1 Score  \\\nModel                                                                          \nExtraTreeClassifier                0.80               0.52    None      0.80   \nQuadraticDiscriminantAnalysis      0.74               0.51    None      0.76   \nDecisionTreeClassifier             0.77               0.51    None      0.78   \nExtraTreesClassifier               0.88               0.50    None      0.83   \nLabelSpreading                     0.79               0.50    None      0.79   \nBaggingClassifier                  0.87               0.50    None      0.82   \nLabelPropagation                   0.79               0.50    None      0.79   \nRidgeClassifier                    0.88               0.50    None      0.83   \nRidgeClassifierCV                  0.88               0.50    None      0.83   \nSGDClassifier                      0.88               0.50    None      0.83   \nLogisticRegression                 0.88               0.50    None      0.83   \nLinearSVC                          0.88               0.50    None      0.83   \nLinearDiscriminantAnalysis         0.88               0.50    None      0.83   \nRandomForestClassifier             0.88               0.50    None      0.83   \nSVC                                0.88               0.50    None      0.83   \nDummyClassifier                    0.88               0.50    None      0.83   \nCalibratedClassifierCV             0.88               0.50    None      0.83   \nBernoulliNB                        0.88               0.50    None      0.83   \nKNeighborsClassifier               0.87               0.50    None      0.82   \nAdaBoostClassifier                 0.88               0.50    None      0.82   \nLGBMClassifier                     0.88               0.50    None      0.82   \nGaussianNB                         0.83               0.50    None      0.81   \nNearestCentroid                    0.55               0.49    None      0.63   \nPerceptron                         0.82               0.49    None      0.80   \nPassiveAggressiveClassifier        0.82               0.49    None      0.80   \n\n                               Time Taken  \nModel                                      \nExtraTreeClassifier                  0.05  \nQuadraticDiscriminantAnalysis        0.05  \nDecisionTreeClassifier               0.11  \nExtraTreesClassifier                 0.85  \nLabelSpreading                       5.63  \nBaggingClassifier                    0.64  \nLabelPropagation                     4.97  \nRidgeClassifier                      0.08  \nRidgeClassifierCV                    0.07  \nSGDClassifier                        0.11  \nLogisticRegression                   0.07  \nLinearSVC                            0.75  \nLinearDiscriminantAnalysis           0.11  \nRandomForestClassifier               0.95  \nSVC                                  2.91  \nDummyClassifier                      0.03  \nCalibratedClassifierCV               3.43  \nBernoulliNB                          0.07  \nKNeighborsClassifier                 0.22  \nAdaBoostClassifier                   1.18  \nLGBMClassifier                       0.27  \nGaussianNB                           0.04  \nNearestCentroid                      0.04  \nPerceptron                           0.04  \nPassiveAggressiveClassifier          0.06  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accuracy</th>\n      <th>Balanced Accuracy</th>\n      <th>ROC AUC</th>\n      <th>F1 Score</th>\n      <th>Time Taken</th>\n    </tr>\n    <tr>\n      <th>Model</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ExtraTreeClassifier</th>\n      <td>0.80</td>\n      <td>0.52</td>\n      <td>None</td>\n      <td>0.80</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>QuadraticDiscriminantAnalysis</th>\n      <td>0.74</td>\n      <td>0.51</td>\n      <td>None</td>\n      <td>0.76</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>DecisionTreeClassifier</th>\n      <td>0.77</td>\n      <td>0.51</td>\n      <td>None</td>\n      <td>0.78</td>\n      <td>0.11</td>\n    </tr>\n    <tr>\n      <th>ExtraTreesClassifier</th>\n      <td>0.88</td>\n      <td>0.50</td>\n      <td>None</td>\n      <td>0.83</td>\n      <td>0.85</td>\n    </tr>\n    <tr>\n      <th>LabelSpreading</th>\n      <td>0.79</td>\n      <td>0.50</td>\n      <td>None</td>\n      <td>0.79</td>\n      <td>5.63</td>\n    </tr>\n    <tr>\n      <th>BaggingClassifier</th>\n      <td>0.87</td>\n      <td>0.50</td>\n      <td>None</td>\n      <td>0.82</td>\n      <td>0.64</td>\n    </tr>\n    <tr>\n      <th>LabelPropagation</th>\n      <td>0.79</td>\n      <td>0.50</td>\n      <td>None</td>\n      <td>0.79</td>\n      <td>4.97</td>\n    </tr>\n    <tr>\n      <th>RidgeClassifier</th>\n      <td>0.88</td>\n      <td>0.50</td>\n      <td>None</td>\n      <td>0.83</td>\n      <td>0.08</td>\n    </tr>\n    <tr>\n      <th>RidgeClassifierCV</th>\n      <td>0.88</td>\n      <td>0.50</td>\n      <td>None</td>\n      <td>0.83</td>\n      <td>0.07</td>\n    </tr>\n    <tr>\n      <th>SGDClassifier</th>\n      <td>0.88</td>\n      <td>0.50</td>\n      <td>None</td>\n      <td>0.83</td>\n      <td>0.11</td>\n    </tr>\n    <tr>\n      <th>LogisticRegression</th>\n      <td>0.88</td>\n      <td>0.50</td>\n      <td>None</td>\n      <td>0.83</td>\n      <td>0.07</td>\n    </tr>\n    <tr>\n      <th>LinearSVC</th>\n      <td>0.88</td>\n      <td>0.50</td>\n      <td>None</td>\n      <td>0.83</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>LinearDiscriminantAnalysis</th>\n      <td>0.88</td>\n      <td>0.50</td>\n      <td>None</td>\n      <td>0.83</td>\n      <td>0.11</td>\n    </tr>\n    <tr>\n      <th>RandomForestClassifier</th>\n      <td>0.88</td>\n      <td>0.50</td>\n      <td>None</td>\n      <td>0.83</td>\n      <td>0.95</td>\n    </tr>\n    <tr>\n      <th>SVC</th>\n      <td>0.88</td>\n      <td>0.50</td>\n      <td>None</td>\n      <td>0.83</td>\n      <td>2.91</td>\n    </tr>\n    <tr>\n      <th>DummyClassifier</th>\n      <td>0.88</td>\n      <td>0.50</td>\n      <td>None</td>\n      <td>0.83</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>CalibratedClassifierCV</th>\n      <td>0.88</td>\n      <td>0.50</td>\n      <td>None</td>\n      <td>0.83</td>\n      <td>3.43</td>\n    </tr>\n    <tr>\n      <th>BernoulliNB</th>\n      <td>0.88</td>\n      <td>0.50</td>\n      <td>None</td>\n      <td>0.83</td>\n      <td>0.07</td>\n    </tr>\n    <tr>\n      <th>KNeighborsClassifier</th>\n      <td>0.87</td>\n      <td>0.50</td>\n      <td>None</td>\n      <td>0.82</td>\n      <td>0.22</td>\n    </tr>\n    <tr>\n      <th>AdaBoostClassifier</th>\n      <td>0.88</td>\n      <td>0.50</td>\n      <td>None</td>\n      <td>0.82</td>\n      <td>1.18</td>\n    </tr>\n    <tr>\n      <th>LGBMClassifier</th>\n      <td>0.88</td>\n      <td>0.50</td>\n      <td>None</td>\n      <td>0.82</td>\n      <td>0.27</td>\n    </tr>\n    <tr>\n      <th>GaussianNB</th>\n      <td>0.83</td>\n      <td>0.50</td>\n      <td>None</td>\n      <td>0.81</td>\n      <td>0.04</td>\n    </tr>\n    <tr>\n      <th>NearestCentroid</th>\n      <td>0.55</td>\n      <td>0.49</td>\n      <td>None</td>\n      <td>0.63</td>\n      <td>0.04</td>\n    </tr>\n    <tr>\n      <th>Perceptron</th>\n      <td>0.82</td>\n      <td>0.49</td>\n      <td>None</td>\n      <td>0.80</td>\n      <td>0.04</td>\n    </tr>\n    <tr>\n      <th>PassiveAggressiveClassifier</th>\n      <td>0.82</td>\n      <td>0.49</td>\n      <td>None</td>\n      <td>0.80</td>\n      <td>0.06</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(x_train_set,x_test_set,y_train,y_test)\n",
    "models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##SUPERVISED##"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f858335e",
   "metadata": {},
   "source": [
    "## Instituto Politécnico de Coimbra\n",
    "## Instituto Superior de Engenharia de Coimbra\n",
    "## Mestrado em Engenharia Informática - Machine Learning\n",
    "## Elaborado por:\n",
    "\n",
    "# André Proença 2016018783\n",
    "\n",
    "# Isabel Castro 2018013160\n",
    "\n",
    "## DATA SET ORIGINAL\n",
    "## [https://archive.ics.uci.edu/ml/datasets/Bank+Marketing](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ae4bcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sea\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import string\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca517ec4",
   "metadata": {},
   "source": [
    "## Used functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67b7de43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randcolor(number):\n",
    "    lista = []\n",
    "    for i in range(number):\n",
    "        color = \"%06x\" % random.randint(0, 0xFFFFFF)\n",
    "        lista.append(color)\n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24794560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotFigureBoxPlot(columnName,dataset):\n",
    "    plt.figure(figsize=(6,9))\n",
    "    sea.boxplot(x=columnName, data=dataset, color='green')\n",
    "    plt.title(\"Boxplot of {}\" .format(columnName),size=20,color=\"red\")\n",
    "    plt.xlabel(\"{}\".format(columnName),size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c2c72ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericAnalysis(columnName, dataframe):\n",
    "    item = dataframe[columnName]\n",
    "\n",
    "    print(\"Mean:\\t\", item.mean())\n",
    "    print(\"Mode:\\t\", item.mode())\n",
    "    print(\"Median:\\t\", item.median())\n",
    "    print(\"Variance:\\t\", item.var())\n",
    "    print(\"Std deviation:\\t\", item.std())\n",
    "    print(\"Percentils (25, 50, 75):\\t\", item.quantile([0, 0.25, 0.5, 0.75, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "559524df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotBarChart(dataset, columnName):\n",
    "    sea.set(style='whitegrid', palette=\"bright\", font_scale=1.1, rc={\"figure.figsize\": [15, 10]})\n",
    "    if(dataset[columnName].dtype != 'object'):\n",
    "        sea.histplot(x=columnName, data=dataset, bins=np.arange(0, 100, 5), kde=True)\n",
    "    else:\n",
    "        sea.histplot(x=columnName, data=dataset, bins=np.arange(0, 100, 5))\n",
    "    plt.title(string.capwords(columnName) + \" \" + \"distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8f695d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPieChart(data, labels, title, color=None):\n",
    "    \n",
    "    \n",
    "    fig1, ax1 = plt.subplots()\n",
    "    if (color == None):\n",
    "        plt.style.use('seaborn-pastel')\n",
    "    ax1.pie(data,\n",
    "            labels=labels,\n",
    "            autopct=\"%.1f%%\",\n",
    "            startangle=90,\n",
    "            colors=color,\n",
    "            pctdistance=0.85)\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    ax1.axis('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "085a45be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotBarChartByAgeRange(dataset, columnName, label, title):\n",
    "    ageRange = list(range(15, 95, 5))\n",
    "\n",
    "    plt.figure(figsize=(18, 25))\n",
    "    plt.subplot(3, 2, 1)\n",
    "    dataset.groupby(pd.cut(dataset.age, ageRange))[columnName].mean().plot.bar()\n",
    "    plt.ylabel(label)\n",
    "    plt.title(title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28296aaa",
   "metadata": {},
   "source": [
    "## Dataset reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2046705",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDataset = pd.read_csv('bank-full.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5ec98e",
   "metadata": {},
   "source": [
    "### Resampling Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f07bd529",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = fullDataset.drop('y',axis=1)\n",
    "Y = fullDataset['y']\n",
    "\n",
    "xData,xdataa,yData,ydataa = train_test_split(X,Y,train_size=0.22,stratify=Y)\n",
    "\n",
    "yData=pd.DataFrame(yData,columns=['y'])\n",
    "dataset = xData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "300b72f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAMOS DAR DROP A TODAS AS LINHAS COM BALANCE NEGATIVO E VAMOS TAMBEM DAR DROP A LINHAS COM BALANCE MUITO ALTOS\n",
    "dataset.drop(dataset[(dataset['balance']>40000)|(dataset['balance']<0)].index,inplace=True,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85c7b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove data where duration is bigger than 2500\n",
    "dataset.drop(dataset[dataset['duration']>2500].index,inplace=True,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bf2337f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove data where campaign is bigger than 35\n",
    "dataset.drop(dataset[dataset['campaign']>35].index,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aff25338",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all pdays data\n",
    "dataset.drop(\"pdays\",inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c8c32dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all data where previous is bigger than 30\n",
    "dataset.drop(dataset[dataset['previous']>30].index,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162d051f",
   "metadata": {},
   "source": [
    "## Stratified sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ebb801a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [9115, 9946]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_18132\\2457080411.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'binary'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'loan'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'default'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m \u001B[0mx_train_set\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx_test_set\u001B[0m \u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_test\u001B[0m  \u001B[1;33m=\u001B[0m \u001B[0mtrain_test_split\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0myData\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtrain_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.8\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrandom_state\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstratify\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'binary'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[1;31m# Remove binary column because it was only an aux for the split\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001B[0m in \u001B[0;36mtrain_test_split\u001B[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001B[0m\n\u001B[0;32m   2415\u001B[0m         \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"At least one array required as input\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2416\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2417\u001B[1;33m     \u001B[0marrays\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mindexable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0marrays\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2418\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2419\u001B[0m     \u001B[0mn_samples\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_num_samples\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marrays\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36mindexable\u001B[1;34m(*iterables)\u001B[0m\n\u001B[0;32m    376\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    377\u001B[0m     \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0m_make_indexable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mX\u001B[0m \u001B[1;32min\u001B[0m \u001B[0miterables\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 378\u001B[1;33m     \u001B[0mcheck_consistent_length\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    379\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    380\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36mcheck_consistent_length\u001B[1;34m(*arrays)\u001B[0m\n\u001B[0;32m    330\u001B[0m     \u001B[0muniques\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munique\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlengths\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    331\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0muniques\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 332\u001B[1;33m         raise ValueError(\n\u001B[0m\u001B[0;32m    333\u001B[0m             \u001B[1;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    334\u001B[0m             \u001B[1;33m%\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ml\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0ml\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mlengths\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Found input variables with inconsistent numbers of samples: [9115, 9946]"
     ]
    }
   ],
   "source": [
    "\n",
    "# Divide dataset between features e target\n",
    "\n",
    "\n",
    "# Test and train must have similar loans value\n",
    "\n",
    "dataset['binary'] = dataset['loan'].astype(str) + dataset['default'].astype(str)\n",
    "\n",
    "x_train_set, x_test_set , y_train, y_test  = train_test_split(dataset,yData,train_size=0.8, random_state=0, stratify=dataset[['binary']])\n",
    "\n",
    "# Remove binary column because it was only an aux for the split\n",
    "x_train_set = x_train_set.drop(\"binary\",axis=1)\n",
    "x_test_set = x_test_set.drop(\"binary\",axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05e7d70",
   "metadata": {},
   "source": [
    "## Enconding categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5723c90",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1028e9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cat = ['age','balance','day','campaign','previous','duration']\n",
    "ordinal_cat = ['month','contact','poutcome']\n",
    "one_hot_cat = ['job','marital','education','default','housing','loan']\n",
    "\n",
    "num_pipe = Pipeline([('scaler',StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline([('onehot',OneHotEncoder(handle_unknown='ignore', sparse=False, drop='if_binary'))])\n",
    "\n",
    "cat_pipe_ordinal = Pipeline([('ordinal_encoder',OrdinalEncoder())])\n",
    "\n",
    "preprocessor = ColumnTransformer([('num_enc',num_pipe,num_cat),('cat_enc',categorical_transformer,one_hot_cat),('ord_enc',cat_pipe_ordinal,ordinal_cat)])\n",
    "\n",
    "x_train_set = preprocessor.fit_transform(x_train_set)\n",
    "x_test_set = preprocessor.fit_transform(x_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05555a0d",
   "metadata": {},
   "source": [
    "### Without pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cd4385",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binary Encoding\n",
    "\n",
    "list_bin = ['default','housing','loan']\n",
    "for i in list_bin:\n",
    "    dataset[i] = LabelBinarizer().fit_transform(dataset[i].values)\n",
    "\n",
    "#Ordinal Encoding\n",
    "\n",
    "list_ordinal=['month','contact','poutcome']\n",
    "for i in list_ordinal:\n",
    "    dataset[i]=LabelEncoder().fit_transform(dataset[i].values)\n",
    "\n",
    "# Dummy Encoding\n",
    "\n",
    "dataset = pd.get_dummies(dataset, columns= ['job','marital','education'])\n",
    "\n",
    "# Reset Index and check dataset again\n",
    "\n",
    "dataset = dataset.reset_index()\n",
    "dataset.drop('index', axis=1, inplace=True)\n",
    "\n",
    "dataset['binary'] = dataset['loan'].astype(str) + dataset['default'].astype(str)\n",
    "\n",
    "x_train_set_np, x_test_set_np , y_train_set_np, y_test_set_np = train_test_split(dataset,datasetTarget,test_size=0.2, random_state=0, stratify=dataset[['binary']])\n",
    "\n",
    "# Binary columns no longer needed\n",
    "x_train_set_np = x_train_set_np.drop(\"binary\",axis=1)\n",
    "x_test_set_np = x_test_set_np.drop(\"binary\",axis=1)\n",
    "\n",
    "\n",
    "#Scaling\n",
    "\n",
    "ss= StandardScaler()\n",
    "\n",
    "x_train_set_np_org = ss.fit_transform(x_train_set_np)\n",
    "x_test_set_np_org = ss.fit_transform(x_test_set_np)\n",
    "\n",
    "x_train_set_np_sc = ss.fit_transform(x_train_set_np[['age','balance','day','duration','campaign','previous']])\n",
    "x_test_set_np_sc = ss.transform(x_test_set_np[['age','balance','day','duration','campaign','previous']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1404f5",
   "metadata": {},
   "source": [
    "#### META 2 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07310d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(x_train_set,x_test_set,y_train,y_test)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107012be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1a3079",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
